# Pod
# Pod Lifecycle
* `Phase`: Pod의 전체 상태를 대표하는 속성 (Pod의 main 상태)
  * Status 안에 Phase 존재하고, 아래 5개의 상태가 존재한다.
  * Pending
  * Running
  * Succeeded
  * Failed
  * Unknown 
* `Conditions`: Pod가 실행되는 단계와 상태를 나타내는 속성
  * 아래 4개의 상태가 존재한다.
  * Initialized
  * ContainerReady
  * PodScheduled
  * Ready
  * `Reason`: Conditions의 세부 내용을 알려주는 항목
    * `status: 'False'`인 경우 실패 원인을 Reason을 통해 파악.
    * ContainersNotReady
    * PodCompleted
* `ContainerStatuses`: 각각의 Container 상태를 대표하는 속성
  * state는 3개의 상태가 존재한다.
    * Wating
    * Running
    * Terminated
  * 세부 내용을 알기 위한 Reason 존재
    * ContainerCreating
    * CrashLoopBackOff
    * Error
    * Completed
* ## Phase - Pending
  * Pod의 최초 상태는 `Pending`이다.
  * InitContainer
    * `initContainer`: 본컨테이너가 기동되기 전에 초기화해야 하는 내용을 담는 컨테이너 
    * volume이나 보안 세팅을 위해 사전 설정을 해야하는 경우 Pod 생성 내용 안에 initContainers라는 항목에 초기화 스크립트를 넣을 수 있다.
    * 위 스크립트가 본 컨테이너보다 먼저 실행이 돼서 작업이 성공적으로 끝났거나, 아예 initContainers 설정을 하지 않은 경우에는 `Initialized: True`로, 아니면 `Initialized: fasle`가 된다.
  * PodScheduled, Image Downloading
    * `Pod`가 어느 `Node`로 올라갈지 스케줄이 완료되면 `PodScheduled: True`
      * Pod가 올라갈 Node를 직접 지정하거나, 쿠버네티스가 자원의 상황에 따라 Node 결정
    * `Image Downloading`: 컨테이너에 이미지를 다운로드하는 동작
    * 위 두 과정동안 Container의 상태는 `Waiting`이고, Reason은 `ContainerCreating`이다.
* ## Phase - Running
  * 컨테이너가 정상적으로 기동되면서 Pod와 컨테이너의 상태는 `Running`이 된다.
  * 컨테이너가 기동 중 문제가 발생하여 재시작되면 `Waiting`, `Reason: CrashLoopBackOff`
  * Pod는 위 컨테이너의 상태를 `Running`으로 간주하지만 내부 Condition `ContainerReady`,`Ready`는 `False이다.
  * 추후 모든 컨테이너들이 정상적으로 기동된다면 Condition들은 모두 True가 된다.
  * ***Pod의 상태가 Running이더라도 내부 컨테이너가 Running이 아닐 수 있으므로 Pod뿐만 아니라 컨테이너의 상태도 모니터링 해야한다.***
* ## Phase - Failed, Succeeded
  * Job이나 CronJob으로 생성된 Pod는 일을 수행중일 때는 Running이지만, 일을 마치면 Pod는 더이상 일을 하지 않는 상태가 된다.
  * 이때 Pod의 상태는 `Failed`, 또는 `Succeeded`가 된다.
  * *Failed*: 작업을 하고 있는 컨테이너 중에 하나라도 문제가 생긴 경우
  * *Succeeded*: 컨테이너가 모두 *Completed*로 작업을 성공적으로 마친 경우
  * Pod의 상태가 *Failed*건, *Succeeded*건 상관없이 `ContainerReady: False`, `Ready: False`로 바뀐다.
* ## Phase - Failed, Unknown
  * Pending 중에 Failed로 상태가 변경될 수 있다.
  * Pending/Running 중에 통신장애가 발생하면 Pod가 *Unknown*상태가 된다. 장애가 빨리 해결되면 기존 상태로 변경되지만, 지속되면 *Failed* 상태가 될 수 있다. 
# ReadinessProbe, LivenessProbe
* `Pod`를 만들면 그 안에 `Container`가 생기고, Pod와 `Container` 상태가 Running이 되면서 컨테이너 내 App도 정상적으로 구동된다.
* `Service`와 `Pod`가 연결이 되고, `Service`의 IP가 외부에 알려지면서 사람들이 `Service`를 통해 접근한다.
* 한 `Service`에 2개의 `Pod`가 연결되어 있으므로 각 `Pod`에 50%씩 트래픽이 나눠진다고 하자.
* `ReadinessProbe` 사용하는 상황
  * Node2가 다운되면 그 위의 Pod2도 Failed이 되고, `Service`로 오는 모든 트래픽은 Node1의 Pod로 전달 된다.
  * 죽은 Pod2는 `Auto Healing`에 의해 다른 Node3에 재생성되려 한다. 
  * Pod2와 컨테이너가 *Running* 상태가 되어 `Service`와 연결되지만, **앱이 구동 준비중(Booting)인 순간이 발생한다. 
  * 이 때, 트래픽이 Pod2로 오게되면 사용자는 에러페이지를 보게 된다.
  * 이 때, `ReadinessProbe`를 주면 문제 해결
  * **ReadinessProbe는 앱이 구동되기 전까지 서비스와 연결이 되지 않도록 해준다.**
  * 앱이 완전히 준비된게 확인되면 서비스와 연결되고, 트래픽은 50%, 50%씩 흐르게 된다.
* `LivenessProbe` 사용하는 상황
  * 위 상황에 이어서 Pod2의 앱에 장애가 난 경우 Pod2로 트래픽이 들어오면 500(INTERNAL SERVER ERROR)가 발생한다.
  * 애플리케이션의 장애를 감지해주는 LivenessProbe를 지정해 문제 해결
  * **LivenessProbe는 앱에 장애가 발생하면 Pod를 재실행해 에러 상태에 머물러 있는 것을 방지한다.**
  * 예시)
    * 서비스를 Tomcat으로 돌릴 때 Tomcat은 작동하지만, 그 위에 띄워진 애플리케이션에 메모리 초과가 발생한 경우
    * 이 경우에는 Tomcat 프로세서 자체가 죽은 것이 아니라 그 위에 있던 애플리케이션에 문제가 생긴 것이기 때문에 Tomcat 프로세서를 지켜보는 Pod는 Running 상태를 유지한다.
    * 이때 Pod로 트래픽이 들어와 해당 어플리케이션에 접근하면 500(INTERNAL SERVER ERROR)가 반환된다.
    * 따라서 `LivenessProbe`를 지정해 Pod를 재실행함으로써 지속적으로 에러 상태에 머물러 있는 것을 방지해준다. (잠깐의 트래픽 에러는 발생함)
* 안정적인 서비스를 유지하기 위해서는 *`ReadinessProbe`를 지정해 애플리케이션 구동 순간에 발생하는 트래픽 실패를 없애고, `LivenessProbe`를 통해 애플리케이션에 장애 발생 시 지속적인 실패를 예방해야 한다.*
